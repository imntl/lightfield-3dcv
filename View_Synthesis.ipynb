{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from models.data_loading import LightFieldDataset\n",
    "from models.VAE_changed import VAE\n",
    "from models.transformations import RandomCrop, ToTensor, Resize\n",
    "from models.ViewSynthesis import Evaluation\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def transformations before loading data\n",
    "transformations = transforms.Compose([\n",
    "                                        #RandomCrop(128), # Change here to use RandomCrop\n",
    "                                        Resize(128),      # or resize\n",
    "                                        ToTensor(),\n",
    "                                      ])\n",
    "test_set = LightFieldDataset(sort=['test'], \n",
    "                              data_kind = 'all', \n",
    "                              root_dir = 'data',\n",
    "                              transform = transformations)\n",
    "\n",
    "#path where the model comes from\n",
    "path = os.path.join(\"final.pth\")\n",
    "\n",
    "#Path where images will be saved\n",
    "path1 = \"Model\" \n",
    "\n",
    "#Get the trained model\n",
    "model = VAE(in_channels=27,\n",
    "            in_size=128,\n",
    "            hidden_dims=[64,256,512])\n",
    "\n",
    "params = model.parameters()\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.AdamW(params, lr=learning_rate)\n",
    "\n",
    "\n",
    "state = torch.load(path, map_location=torch.device('cpu'))\n",
    "state = torch.load(path)                         # use this instead, if GPU available\n",
    "model.load_state_dict(state['model'])\n",
    "optimizer.load_state_dict(state['optimizer'])\n",
    "model.eval()\n",
    "for state in optimizer.state.values():           # May be needed if GPU available \n",
    "    for k, v in state.items():                   # (maybe not, I'm not sure. Might only be needed for training)\n",
    "        if torch.is_tensor(v):\n",
    "            state[k] = v.cuda()\n",
    "            \n",
    "\n",
    "# Evaluate the model            \n",
    "eval = Evaluation(model, test_set, reverse=True)\n",
    "eval.plot_evaluation()\n",
    "eval.save_synthesized_views(path1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
